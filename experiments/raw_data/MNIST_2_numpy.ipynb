{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "227ffd0d-984d-4c14-b9aa-fe69fce70172",
   "metadata": {},
   "source": [
    "# Get the MNIST data and save it as separate serialized numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410fcc1a-abc8-4a91-bff9-d600030fb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES = \"train-images.idx3-ubyte\"\n",
    "TRAIN_LABELS = \"train-labels.idx1-ubyte\"\n",
    "TEST_IMAGES = \"t10k-images.idx3-ubyte\"\n",
    "TEST_LABELS = \"t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa7061-d398-4d0f-8a4d-8dd53f873f84",
   "metadata": {},
   "source": [
    "### Load the data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99354e6f-9652-49e4-98e8-dc7fe2595742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xavier/PycharmProjects/mnist-overkill/experiments/raw_data\n"
     ]
    }
   ],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "data_train = idx2numpy.convert_from_file(TRAIN_IMAGES)\n",
    "# arr is now a np.ndarray type of object of shape 60000, 28, 28\n",
    "labels_train = idx2numpy.convert_from_file(TRAIN_LABELS)\n",
    "data_test = idx2numpy.convert_from_file(TEST_IMAGES)\n",
    "labels_test = idx2numpy.convert_from_file(TEST_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ffeede-aa67-4756-bdea-96fcb704788b",
   "metadata": {},
   "source": [
    "### Create CSV files for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec805c2-c7b3-4ac0-b5b9-919da88c9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label\n",
      "0          5\n",
      "1          0\n",
      "2          4\n",
      "3          1\n",
      "4          9\n",
      "...      ...\n",
      "59995      8\n",
      "59996      3\n",
      "59997      5\n",
      "59998      6\n",
      "59999      8\n",
      "\n",
      "[60000 rows x 1 columns]\n",
      "      label\n",
      "0         7\n",
      "1         2\n",
      "2         1\n",
      "3         0\n",
      "4         4\n",
      "...     ...\n",
      "9995      2\n",
      "9996      3\n",
      "9997      4\n",
      "9998      5\n",
      "9999      6\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dataframe with a single column 'label'\n",
    "df_train = pd.DataFrame(columns=['label'])\n",
    "df_train['label'] = labels_train\n",
    "print(df_train)\n",
    "\n",
    "df_test = pd.DataFrame(columns=['label'])\n",
    "df_test['label'] = labels_test\n",
    "print(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f740d5-720e-4fec-bde9-6857977fde71",
   "metadata": {},
   "source": [
    "### Make 6 different subsets of the data, increasing by 10k each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605f2913-4e2b-4c21-8bec-e3970ba3e693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 1: Length = 10000\n",
      "Subset 2: Length = 20000\n",
      "Subset 3: Length = 30000\n",
      "Subset 4: Length = 40000\n",
      "Subset 5: Length = 50000\n",
      "Subset 6: Length = 60000\n",
      "      label\n",
      "0         5\n",
      "1         0\n",
      "2         4\n",
      "3         1\n",
      "4         9\n",
      "...     ...\n",
      "9995      5\n",
      "9996      8\n",
      "9997      6\n",
      "9998      9\n",
      "9999      7\n",
      "\n",
      "[10000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "subsets = []\n",
    "subset_lengths = [10000, 20000, 30000, 40000, 50000, 60000]\n",
    "# Create subsets\n",
    "for length in subset_lengths:\n",
    "    subset = df_train[:length].copy()  # Slice the DataFrame to the desired length\n",
    "    subsets.append(subset)\n",
    "\n",
    "# Print the lengths of each subset\n",
    "for i, subset in enumerate(subsets, 1):\n",
    "    print(f\"Subset {i}: Length = {len(subset)}\")\n",
    "\n",
    "print(subsets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c157fd1-4dfa-4abc-9712-5e23b521f4db",
   "metadata": {},
   "source": [
    "### Write the images out to an output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45e8e900-e0c6-44ef-a387-0de54865b83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xavier/MNIST/train\n",
      "/home/xavier/MNIST/test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = os.path.join(os.path.expanduser('~'), 'MNIST')\n",
    "output_dir_train = os.path.join(OUTPUT_DIR, 'train')\n",
    "output_dir_test = os.path.join(OUTPUT_DIR, 'test')\n",
    "print(output_dir_train)\n",
    "print(output_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2aeb37-b882-4e8d-a0d4-1a3be1cbf6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# train\n",
    "for i, img in enumerate(data_train):\n",
    "    savepath = os.path.join(output_dir_train, f'{i}.npy')\n",
    "    np.save(savepath, img)\n",
    "\n",
    "# test\n",
    "for i, img in enumerate(data_test):\n",
    "    savepath = os.path.join(output_dir_test, f'{i}.npy')\n",
    "    np.save(savepath, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e9ca3-04e8-4cbf-aca1-0d0cae14471e",
   "metadata": {},
   "source": [
    "### Write the train labels subsets to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb7fda9-465d-43b2-baaa-d2b866c3a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_subset in enumerate(subsets):\n",
    "    savepath = os.path.join(OUTPUT_DIR, f'labels_{(i+1) * 10}k.csv')\n",
    "    df_subset.to_csv(savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0e13a-27a5-49cc-99f8-1c3701b7fda2",
   "metadata": {},
   "source": [
    "### Write the test labels to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa50a28-870b-4047-a784-0a5787e9804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(os.path.join(OUTPUT_DIR, f'labels_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff42ac-96a7-44c9-9db4-b5134075211d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Overkill Environment",
   "language": "python",
   "name": "overkillenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
